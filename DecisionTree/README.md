Initially, the plan was to utilize only the genetic algorithm for predicting the Oscar nominees and winners. However, it became clear later that this would provide no point of comparison for the genetic algorithm, which could be very problematic if the genetic algorithm underperformed. Using Sckit-Learn, three different machine learning classifiers were tested as possibilities: multilayer perceptron (MLP) classifier, decision tree classifier, and random forest classifier. The MLP classifier is a neural network model that learns a function by training on a dataset (the 2016 movie information, in our case), and then utilizes this function to predict output on new data. A decision tree classifier is a supervised learning method that repeatedly divides the training data into smaller subsets based off of splits in the data for various features. When a subset of the data eventually is all of the same output class, the splitting ends and a leaf node of this specific class is created. This process results in the construction of a tree, and the testing data is run through this same tree. When an instance of testing data reaches a leaf node, it is given the class of that node. The random forest classifier creates a specified number of decision trees (1000, in our case), and trains these on different sub-samples of the training data. When testing data is run on a random forest classifier, the resulting classifications from these decision trees is averaged for the final prediction. Due to its large sample of trees, random forest classifiers can have superior accuracy over a normal decision tree, and its property of training on sub-samples of the data can help control for over-fitting.
To test the predictive capabilities of the Twitter data, the first trials were conducted with only the tweet count ratio and box office revenue. Box office revenue was included to control for movies whose tweet count ratios were unreliable since they were calculated based off a very low number of tweets. For example, if a movie was tweeted about once during it’s week of release, and two times during the week before the Oscar nominations announcement, the calculated tweet count ratio of 2 would be very high, even though this difference was likely due to chance. The inclusion of box office data ensured that movies that barely anyone had seen would be disregarded, even if they had a high tweet count ratio. To ensure accuracy, 100 iterations of fitting and training were performed for each model. For a later trial, the process remained same, except release date was added as a third feature. To develop a more successful predictive model, a final trial was performed where more features were now added to the model, including Metacritic critics and user score, whether a movie was a Golden Globe best picture nominee, whether a movie was a Critics’ Choice best picture nominee, the number of theaters a movie was played in, and the tweet sentiment ratio. In each of these trials, all three classifiers were run on this data and compared in terms of accuracy.
This folder contains all of the code necessary to run the random forest classifier. A lot of the files in this folder are used to parse, normalize, and reformat the data. One of the files is used to actually run the training and testing of the random forest classifier.  

